# ğŸ¦¾ Assistente de Acessibilidade Visual

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Snapdragon](https://img.shields.io/badge/Optimized%20for-Snapdragon-red.svg)](https://www.qualcomm.com/products/mobile/snapdragon)

Sistema de **inteligÃªncia artificial** que detecta objetos em tempo real e os anuncia em portuguÃªs para pessoas com deficiÃªncia visual. Desenvolvido para dispositivos **Snapdragon** com foco em **acessibilidade** e **independÃªncia**.

## ğŸ¯ DescriÃ§Ã£o

O **Assistente de Acessibilidade Visual** Ã© uma soluÃ§Ã£o inovadora que combina visÃ£o computacional e sÃ­ntese de voz para criar "olhos digitais" que descrevem o ambiente ao usuÃ¡rio. O sistema detecta pessoas, veÃ­culos e objetos, calculando sua posiÃ§Ã£o e distÃ¢ncia, e anuncia essas informaÃ§Ãµes em portuguÃªs brasileiro.

### âœ¨ Funcionalidades

- ğŸ¯ **DetecÃ§Ã£o em tempo real** de pessoas, carros, Ã´nibus, bicicletas, semÃ¡foros e objetos
- ğŸ—£ï¸ **SÃ­ntese de voz em portuguÃªs** com anÃºncios contextuais
- ğŸ“ **CÃ¡lculo de posiÃ§Ã£o** (esquerda, direita, frente) e distÃ¢ncia (prÃ³ximo, distante)
- ğŸ–¥ï¸ **Interface visual** com caixas de detecÃ§Ã£o coloridas
- ğŸ”’ **100% offline** - funciona sem conexÃ£o com internet
- âš¡ **Otimizado para Snapdragon** - preparado para NPU

### ğŸ› ï¸ Tecnologias Utilizadas

- **YOLO v8** (Ultralytics) - DetecÃ§Ã£o de objetos
- **OpenCV** - Processamento de vÃ­deo e interface
- **pyttsx3** - SÃ­ntese de voz em portuguÃªs
- **NumPy** - Processamento numÃ©rico
- **Threading** - Processamento paralelo
- **Python 3.8+** - Linguagem principal

## ğŸ‘¥ Equipe

| Nome | E-mail |
|------|--------|
| **Luiz Felipe** | luizfmc12@gmail.com |
| **Giovanni Ghiotto** | giovannighiotto10@gmail.com |
| **Daniela Oliveira** | danyela7519@gmail.com |
| **Flavio Diniz Fontanesi** | flavio.d.fontanesi@gmail.com |
| **Guilherme Soares Leite Coelho** | guilhermeslcoelho@gmail.com |
| **Arlen Ricardo Pereira** | arlen.ricardo@gmail.com |

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8 ou superior
- Webcam conectada
- Windows (para sÃ­ntese de voz nativa)
- 4GB RAM mÃ­nimo

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/of3lps/assistente-acessibilidade-visual.git
cd assistente-acessibilidade-visual
```

### 2. Instale as dependÃªncias

```bash
pip install -r requirements_final.txt
```

### 3. Execute o sistema

```bash
python assistente_com_voz.py
```

## ğŸ“– Como Usar

1. **Inicie o programa** executando `python assistente_com_voz.py`
2. **Posicione a cÃ¢mera** para capturar o ambiente desejado
3. **Escute os anÃºncios** em portuguÃªs sobre objetos detectados
4. **Pressione 'q'** para encerrar o programa

### Exemplos de AnÃºncios

- *"pessoa muito prÃ³ximo na frente"*
- *"carro prÃ³ximo na direita"*
- *"Ã´nibus distante na esquerda"*
- *"semÃ¡foro na frente"*

## ğŸ—ï¸ Arquitetura do Sistema

```
assistente_com_voz.py
â”œâ”€â”€ YOLO v8 (DetecÃ§Ã£o)
â”œâ”€â”€ OpenCV (VÃ­deo/Interface)
â”œâ”€â”€ Algoritmos ProprietÃ¡rios
â”‚   â”œâ”€â”€ CÃ¡lculo de PosiÃ§Ã£o
â”‚   â””â”€â”€ Estimativa de DistÃ¢ncia
â”œâ”€â”€ pyttsx3 (SÃ­ntese de Voz)
â””â”€â”€ Threading (Processamento Paralelo)
```

## ğŸ“Š Performance

- **LatÃªncia**: ~200ms por detecÃ§Ã£o
- **FPS**: 30 (cÃ¢mera) + 6 (processamento)
- **PrecisÃ£o**: 85%+ em condiÃ§Ãµes normais
- **Consumo**: CPU moderado, otimizado para mobile

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar Sensibilidade
```python
# No arquivo assistente_com_voz.py, linha 45
if conf > 0.4:  # Altere para 0.3 (mais sensÃ­vel) ou 0.6 (menos sensÃ­vel)
```

### Modificar FrequÃªncia de Processamento
```python
# Linha 140
if frame_count % 5 == 0:  # Altere 5 para processar mais/menos frames
```

### Personalizar Velocidade da Voz
```python
# Linha 18
self.tts.setProperty('rate', 150)  # Altere para 100-200
```

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -m 'feat: adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

### PadrÃ£o de Commits (Conventional Commits)

- `feat:` nova funcionalidade
- `fix:` correÃ§Ã£o de bug
- `docs:` documentaÃ§Ã£o
- `style:` formataÃ§Ã£o
- `refactor:` refatoraÃ§Ã£o
- `test:` testes
- `chore:` tarefas de build/config

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a **MIT License** - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ† Edge AI Developer Hackathon

Projeto desenvolvido para o **Edge AI Developer Hackathon** com foco em **acessibilidade** e **inclusÃ£o digital**.

### Objetivos AlcanÃ§ados

- âœ… Sistema funcional de acessibilidade visual
- âœ… DetecÃ§Ã£o de objetos em tempo real
- âœ… SÃ­ntese de voz em portuguÃªs
- âœ… Interface intuitiva e responsiva
- âœ… CÃ³digo otimizado para Snapdragon
- âœ… SoluÃ§Ã£o 100% offline

## ğŸ“ Suporte

Para dÃºvidas, sugestÃµes ou problemas:

- ğŸ“§ E-mail: luizfmc12@gmail.com
- ğŸ› Issues: [GitHub Issues](https://github.com/of3lps/assistente-acessibilidade-visual/issues)
- ğŸ“– Wiki: [DocumentaÃ§Ã£o Completa](https://github.com/of3lps/assistente-acessibilidade-visual/wiki)

---

**"Transformando visÃ£o artificial em independÃªncia real"** ğŸ¦¾

Desenvolvido com â¤ï¸ para a comunidade de pessoas com deficiÃªncia visual.